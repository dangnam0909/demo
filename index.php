<!DOCTYPE html>
<html lang="ja">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Title</title>
    <link rel="stylesheet" href="assets/css/style.css">
    <link rel="stylesheet" href="assets/css/index.css">
</head>

<body>
    <header id="header_menu">
        <div class="header_top">
            <div class="header_logo" id="menu">
                <h1><a href="./">押上ウィステリア歯科</a></h1>
                <nav>
                    <ul>
                        <li>
                            <a href="#section__title">お知らせ<span>News</span></a>
                        </li>
                        <li>
                            <a href="#section__about">押上ウィステリア歯科について<span>About Clinic</span></a>
                        </li>
                        <li>
                            <a href="#section__outservice">診療案内<span>Guide</span></a>
                        </li>
                        <li>
                            <a href="#section__content">予約<span>Appointment</span></a>
                        </li>
                        <li>
                            <a href="#section__contact">アクセス<span>Access</span></a>
                        </li>
                        <li>
                            <a href="#section__googlemap">GoogleMap<span>GoogleMap</span></a>
                        </li>
                    </ul>
                </nav>
            </div>
        </div>
    </header>
    <main>
        <section id="section__title">
            <div class="container">
                <h2 class="about_title">お知らせ</h2>
                <p class="p_text">
                    The human in-the-loop process is a way to generate features using domain experts. Using domain
                    experts to come up with features is not a novel concept. However, the specific interfaces and method
                    which helps the domain experts create the features are most likely novel.
                    In this case the features the experts create are equivalent to regular expressions. Removing
                    non-alphabetical characters and matching on "smokesppd" is equal to the regular expression
                    /smokes[^a-zA-Z]*ppd/. Using regular expressions as features for text classification is not novel.
                    Given these features the classifier is a manually set threshold by the authors, decided by the
                    performance on a set of documents. This is a classifier, it's just that the parameters of the
                    classifier, in this case a threshold, is set manually. Given the same features and documents almost
                    any machine learning algorithm should be able to find the same threshold or (more likely) a better
                    one.
                    The authors note that using support vector machines (SVM) and hundreds of documents give inferior
                    performance, but does not specify which features or documents the SVM was trained/tested on. A fair
                    comparison would use the same features and document sets as those used by the manual threshold
                    classifier.
                </p>
            </div>
        </section>
        <section id="section__about">
            <div class="container">
                <h2 class="about_title">STUDIO</h2>
                <ul id="scroller">
                    <li><a href="#"><span class="herehover">新宿スタジオ</span><img src="assets/img/studio/ikebukuro1.jpeg"
                                width="290" height="200" alt=""></a></li>
                    <li><a href="#"><span class="herehover">新宿スタジオ</span><img src="assets/img/studio/ikebukuro2.jpeg"
                                width="290" height="200" alt=""></a></li>
                    <li><a href="#"><span class="herehover">新宿スタジオ</span><img src="assets/img/studio/ikebukuro3.jpeg"
                                width="290" height="200" alt=""></a></li>
                    <li><a href="#"><span class="herehover">新宿スタジオ</span><img src="assets/img/studio/ikebukuro4.jpeg"
                                width="290" height="200" alt=""></a></li>
                    <li><a href="#"><span class="herehover">新宿スタジオ</span><img src="assets/img/studio/img_101.jpg"
                                width="290" height="200" alt=""></a></li>
                    <li><a href="#"><span class="herehover">新宿スタジオ</span><img src="assets/img/studio/img_102.jpg"
                                width="290" height="200" alt=""></a></li>
                </ul>
                <a href="#" class="btn btn_readmore readmore_v1"><span>READMORE</span></a>
            </div>
        </section>
        <section id="section__outservice">
            <div class="container">
                <h2 class="about_title">診療案内</h2>
                <p class="p_text">
                    The human in-the-loop process is a way to generate features using domain experts. Using domain
                    experts to come up with features is not a novel concept. However, the specific interfaces and method
                    which helps the domain experts create the features are most likely novel.
                    In this case the features the experts create are equivalent to regular expressions. Removing
                    non-alphabetical characters and matching on "smokesppd" is equal to the regular expression
                    /smokes[^a-zA-Z]*ppd/. Using regular expressions as features for text classification is not novel.
                    Given these features the classifier is a manually set threshold by the authors, decided by the
                    performance on a set of documents. This is a classifier, it's just that the parameters of the
                    classifier, in this case a threshold, is set manually. Given the same features and documents almost
                    any machine learning algorithm should be able to find the same threshold or (more likely) a better
                    one.
                    The authors note that using support vector machines (SVM) and hundreds of documents give inferior
                    performance, but does not specify which features or documents the SVM was trained/tested on. A fair
                    comparison would use the same features and document sets as those used by the manual threshold
                    classifier.
                </p>
            </div>
        </section>
        <section id="section__content">
            <div class="container">
                <h2 class="about_title">予約</h2>
                <p class="p_text">
                    The human in-the-loop process is a way to generate features using domain experts. Using domain
                    experts to come up with features is not a novel concept. However, the specific interfaces and method
                    which helps the domain experts create the features are most likely novel.
                    In this case the features the experts create are equivalent to regular expressions. Removing
                    non-alphabetical characters and matching on "smokesppd" is equal to the regular expression
                    /smokes[^a-zA-Z]*ppd/. Using regular expressions as features for text classification is not novel.
                    Given these features the classifier is a manually set threshold by the authors, decided by the
                    performance on a set of documents. This is a classifier, it's just that the parameters of the
                    classifier, in this case a threshold, is set manually. Given the same features and documents almost
                    any machine learning algorithm should be able to find the same threshold or (more likely) a better
                    one.
                    The authors note that using support vector machines (SVM) and hundreds of documents give inferior
                    performance, but does not specify which features or documents the SVM was trained/tested on. A fair
                    comparison would use the same features and document sets as those used by the manual threshold
                    classifier.
                </p>
            </div>
        </section>
        <section id="section__contact">
            <div class="container">
                <h2 class="about_title">アクセス</h2>
                <p class="p_text">
                    The human in-the-loop process is a way to generate features using domain experts. Using domain
                    experts to come up with features is not a novel concept. However, the specific interfaces and method
                    which helps the domain experts create the features are most likely novel.
                    In this case the features the experts create are equivalent to regular expressions. Removing
                    non-alphabetical characters and matching on "smokesppd" is equal to the regular expression
                    /smokes[^a-zA-Z]*ppd/. Using regular expressions as features for text classification is not novel.
                    Given these features the classifier is a manually set threshold by the authors, decided by the
                    performance on a set of documents. This is a classifier, it's just that the parameters of the
                    classifier, in this case a threshold, is set manually. Given the same features and documents almost
                    any machine learning algorithm should be able to find the same threshold or (more likely) a better
                    one.
                    The authors note that using support vector machines (SVM) and hundreds of documents give inferior
                    performance, but does not specify which features or documents the SVM was trained/tested on. A fair
                    comparison would use the same features and document sets as those used by the manual threshold
                    classifier.
                </p>
            </div>
        </section>
        <section id="section__googlemap">
            <div class="container">
                <h2 class="about_title">GOOGLE MAP</h2>
                <p class="p_text">
                    The human in-the-loop process is a way to generate features using domain experts. Using domain
                    experts to come up with features is not a novel concept. However, the specific interfaces and method
                    which helps the domain experts create the features are most likely novel.
                    In this case the features the experts create are equivalent to regular expressions. Removing
                    non-alphabetical characters and matching on "smokesppd" is equal to the regular expression
                    /smokes[^a-zA-Z]*ppd/. Using regular expressions as features for text classification is not novel.
                    Given these features the classifier is a manually set threshold by the authors, decided by the
                    performance on a set of documents. This is a classifier, it's just that the parameters of the
                    classifier, in this case a threshold, is set manually. Given the same features and documents almost
                    any machine learning algorithm should be able to find the same threshold or (more likely) a better
                    one.
                    The authors note that using support vector machines (SVM) and hundreds of documents give inferior
                    performance, but does not specify which features or documents the SVM was trained/tested on. A fair
                    comparison would use the same features and document sets as those used by the manual threshold
                    classifier.
                </p>
            </div>
        </section>
    </main>
    <p id="gototop">
        <a href="#" title="back to top" class="back2Top">back to top</a>
    </p>
    <footer class="footer">
        <div class="container">
            <div class="row">
                <div class="col-12 footer_sp">
                    <div class="footer-left"> 		 									
                        <li><a href="./#section__title" title="お知らせ">お知らせ</a><span class="sp_footer"><img src="./assets/img/studio/icon06.png" alt=""></span></li>
                        <li><a href="./#section__about" title="押上ウィステリア歯科について">押上ウィステリア歯科について</a><span class="sp_footer"><img src="./assets/img/studio/icon06.png" alt=""></span></li>
                        <li><a href="./#section__outservice" title="診療案内">診療案内</a><span class="sp_footer"><img src="./assets/img/studio/icon06.png" alt=""></span></li>
                        <li><a href="./#section__content" title="予約">予約</a><span class="sp_footer"><img src="./assets/img/studio/icon06.png" alt=""></span></li>
                        <li><a href="./#section__contact" title="アクセス">アクセス</a><span class="sp_footer"><img src="./assets/img/studio/icon06.png" alt=""></span></li>
                        <li class="bdr"><a href="./#section__googlemap" title="GoogleMap">GoogleMap</a></li>
                    </div>
                    <hr class="hr_footer">
                    <div class="footer-right">
                        <small class="copyright cp">Copyright &copy; <span class="year"></span>&nbsp; 押上ウィステリア歯科</small>
                    </div>
                </div>
            </div>
        </div>
    </footer>
    <script type="text/javascript" src="http://ajax.googleapis.com/ajax/libs/jquery/1.4/jquery.min.js"></script>
    <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
    <script type="text/javascript" src="assets/jquery/jquery.simplyscroll.js"></script>
    <link rel="stylesheet" href="assets/jquery/jquery.simplyscroll.css" media="all" type="text/css">
    <script type="text/javascript">
    (function($) {
        $(function() {
            $("#scroller").simplyScroll({
                pauseOnTouch: true,
                pauseOnHover: true
            });
        });
    })(jQuery);
    </script>
    <script src="./assets/js/header.js"></script>
    <script src="./assets/js/main.js"></script>
</body>

</html>